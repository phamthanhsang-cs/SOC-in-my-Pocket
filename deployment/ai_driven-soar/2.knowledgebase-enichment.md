<h1 align="center">

SOCIMP Knowledgebase Enrichment 
</h1>

![Knowledgebase-Enrichment](/images/n8n/Knowledgebase-Enrichment.svg)

<div align="center"> 
  Semi-automated Knowledgebase Enrichment
</div>

## The Challenge

If you’ve seen [my very first SOAR workflow](/deployment/ai_driven-soar/1.workflow#1-case-ingestion.md), we successfully generated AI-powered messages and posted them into TheHive’s comment panel. That moment felt like having our own version of ChatGPT integrated directly into our case management platform.

This achievement led to a new idea: building a workflow, and eventually a chatbot within TheHive to help SOC analysts investigate cases more efficiently and effectively.

However, while creating a simple chatbot is relatively easy, embedding one inside TheHive with awareness of internal environment data is much more complex.

## The Idea

While reading TheHive5 API documentation, I discovered that we can configure webhooks to trigger on various events (e.g., Case Created, Deleted, Merged, Alert Created, Deleted, etc.).

This opened up a new possibility: using a webhook that triggers when a comment is added to a case, allowing us to create an AI chatbot that reacts to analyst inputs.

But before jumping ahead to chatbot development, I realized a prerequisite was needed—a proper knowledge base. This led me into deeper research.

That’s where **RAG - Retrieval-Augmented Generation** comes in to solve the problem.

According [Amazon Web Service](https://aws.amazon.com/what-is/retrieval-augmented-generation/)

>"**Retrieval-Augmented Generation (RAG)** is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response. Large Language Models (LLMs) are trained on vast volumes of data and use billions of parameters to generate original output for tasks like answering questions, translating languages, and completing sentences. RAG extends the already powerful capabilities of LLMs to specific domains or an organization's internal knowledge base, all without the need to retrain the model. It is a cost-effective approach to improving LLM output so it remains relevant, accurate, and useful in various contexts."

Another key concept from AWS is how to build the "knowledge base"

>**Create external data**
>
>The new data outside of the LLM's original training data set is called external data. It can come from multiple data sources, such as a APIs, databases, or document repositories. The data may exist in various formats like files, database records, or long-form text. Another AI technique, called embedding language models, converts data into numerical representations and stores it in a vector database. This process creates a knowledge library that the generative AI models can understand.

## About the Workflow Itself

By taking advantages of **embedding language models**, I designed a simple workflow to store internal knowledge in a vector database.

To manage SOCIMP project-related information (e.g., network diagrams, subnet details, host naming conventions), I chose Google Drive as the document repository. It’s cloud-based, easy to use, and free—perfect for this use case.

Whenever a file (document, image, CSV, JSON, etc.) is added or updated in a specific Google Drive folder (The "Knowledgebase" folder), the workflow is triggered via the [Google Drive API](https://developers.google.com/workspace/drive/api/guides/about-sdk).

After retrieving metadata such as the file ID and filename, the workflow downloads the file and extracts its contents. These contents are then embedded and stored in a vector database.

For the vector database, I chose [Pinecone](https://www.pinecone.io/). It’s free within usage limits, and its performance is more than sufficient for this project.

Pinecone node will handle the jobs for us:
- Chunking the document into manageable sections
- Converting those chunks into high-dimensional vectors (embeddings) 
- And storing everything efficiently—ready for real-time retrieval when an internal knowledge query is made.

## Workflow in Details

### Stage 1: Retrieve document metadata

<div align="center">
  <img src="/images/n8n/pic7.png" alt="pic7" />
</div>